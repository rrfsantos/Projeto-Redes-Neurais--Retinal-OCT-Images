{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Convolutional_Retinal.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3-final"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrfsantos/Projeto-Redes-Neurais-OCT-Images/blob/main/Convolutional_OCT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEW4TLUM6yif"
      },
      "source": [
        "# Convolutional Neural Network, Data Augmentation, Transfer Learning\n",
        "### Task: Automated methods to detect and classify human diseases from medical images.\n",
        "### Dataset:  Labeled Optical Coherence Tomography (OCT) Images for Classification - Kermany, Daniel; Zhang, Kang; Goldbaum, Michael (2018), “Labeled Optical Coherence Tomography (OCT) and Chest X-Ray Images for Classification”, Mendeley Data, v2 http://dx.doi.org/10.17632/rscbjbr9sj.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GbF_Db-6yih"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from imutils import paths\n",
        "import cv2\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.utils import plot_model\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "7qHK26PC6yip"
      },
      "source": [
        "## Visualização dos os dados\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOC74PdhomN9"
      },
      "source": [
        "#!pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrkEfFJOD-8F"
      },
      "source": [
        "#from google.colab import files\r\n",
        "#files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7Ai1WFdED3E"
      },
      "source": [
        "#!mkdir -p ~/.kaggle\r\n",
        "#!cp kaggle.json ~/.kaggle/\r\n",
        "#!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqKYdjlNEF2B"
      },
      "source": [
        "#!kaggle datasets download -d paultimothymooney/kermany2018 -p /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcopwMTeEO-Q"
      },
      "source": [
        "!unzip /content/kermany2018.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VzLHxvqVzDJ"
      },
      "source": [
        "#import shutil\r\n",
        "#shutil.rmtree('/content/oct2017')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNbN51gtAceb"
      },
      "source": [
        "### Visualização de 4 imagens de cada classe do dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lAKTaXKAcec"
      },
      "source": [
        "train_path = '/content/OCT2017/train/'\n",
        "test_path = '/content/OCT2017/test/'\n",
        "\n",
        "classes = ['CNV', 'DME', 'DRUSEN', 'NORMAL']\n",
        "\n",
        "cnv_images = glob.glob(train_path + 'CNV/*', recursive=True)\n",
        "dme_images = glob.glob(train_path + 'DME/*',recursive=True)\n",
        "drusen_images = glob.glob(train_path + 'DRUSEN/*',recursive=True)\n",
        "normal_images = glob.glob(train_path + 'NORMAL/*',recursive=True)\n",
        "\n",
        "images = cnv_images[:4] + dme_images[:4] + drusen_images[:4] + normal_images[:4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9VoYELfAcec"
      },
      "source": [
        "fig=plt.figure(figsize=(15, 15))\n",
        "columns = 4\n",
        "rows = 4\n",
        "for i in range(columns*rows):\n",
        "    img = plt.imread(images[i])\n",
        "    ax = fig.add_subplot(rows, columns, i+1)\n",
        "    if i%4==0:\n",
        "        plt.ylabel(classes[int(i/4)], fontsize=16)\n",
        "    plt.imshow(img, cmap='jet')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ97d5EqAced"
      },
      "source": [
        "### Verificação da distribuição das classes no dataset --> O dataset está desbalanceado!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNlDhmvCAcee"
      },
      "source": [
        "total_cnv_samples = len(cnv_images)\n",
        "total_dme_samples = len(dme_images)\n",
        "total_drusen_samples = len(drusen_images)\n",
        "total_normal_samples = len(normal_images)\n",
        "\n",
        "sample_distribution = [total_cnv_samples, total_dme_samples, total_drusen_samples, total_normal_samples]\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(classes, sample_distribution)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxDM0rcXAcee"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Zv5OW9aAcee"
      },
      "source": [
        "batchSize = 32\n",
        "width = 150\n",
        "height = 150\n",
        "init_lr = 1e-3\n",
        "epochs = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvxi3Al6Acef"
      },
      "source": [
        "trainDataGen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=9,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    validation_split=0.1\n",
        ")\n",
        "\n",
        "trainGenerator = trainDataGen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(width, height),\n",
        "    batch_size=batchSize,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validationGenerator = trainDataGen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(width, height),\n",
        "    batch_size=batchSize,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False,\n",
        "    subset='validation'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgPwwu816yi3"
      },
      "source": [
        "# Balanceamento do dataset - não aumenta as amostras, mas atribui pesos a cada classe para evitar qualquer viés por meio de dados não balanceados (class_weights), os pesos são passados para o model.fit\n",
        "counter = Counter(trainGenerator.classes)                          \n",
        "max_val = float(max(counter.values()))  \n",
        "class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}                     \n",
        "\n",
        "weights = np.fromiter(class_weights.values(), dtype=float)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(classes, sample_distribution*weights) # Distribuição das classes com o ajuste dos pesos (class_weights)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srCsYrr6NFku"
      },
      "source": [
        "# VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIRNKSFNAceg"
      },
      "source": [
        "## Construção do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5lt0Rkd6yi7"
      },
      "source": [
        "# Remover as camadas FC (Full Connected) do modelo VGG-16 pré-treinado - carregar a rede VGG16,\n",
        "#certificando-se de que os conjuntos de camadas principais Full Connected (FC) sejam deixados de fora\n",
        "baseModel = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(width, height, 3)))\n",
        "\n",
        "# Construir as camadas Full Connected (FC) \"top\" do modelo, que substituirão a base da VGG16\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(512, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(64, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(4, activation=\"softmax\")(headModel) # quatro categorias\n",
        "\n",
        "# Construir o modelo CNN\n",
        "modelV = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "# Faz um loop sobre todas as camadas no modelo base e as congela para que * não * sejam atualizadas durante o primeiro processo de treinamento\n",
        "for layer in baseModel.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compilar o modelo\n",
        "opt = Adam(lr=init_lr, decay=init_lr / epochs)\n",
        "modelV.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "\n",
        "plot_model(modelV)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWnDwUIwNMD7"
      },
      "source": [
        "## Treinamento do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd58-hhAAceg"
      },
      "source": [
        "# Callbacks\n",
        "es = EarlyStopping(patience=10,monitor=\"val_loss\")\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', patience=10)\n",
        "mc = ModelCheckpoint(filepath='best.h5', save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EzvTPm9Aceh"
      },
      "source": [
        "stepsValidation = validationGenerator.samples // batchSize\n",
        "stepsTraining = trainGenerator.samples // batchSize\n",
        "\n",
        "historyV = modelV.fit_generator(generator = trainGenerator,\n",
        "    steps_per_epoch = stepsTraining,\n",
        "    epochs=epochs,\n",
        "    validation_data = validationGenerator,\n",
        "    validation_steps = stepsValidation,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[es,rlr,mc]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3c7NEZfNUKC"
      },
      "source": [
        "## Avaliação do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LNceEW2sxwA"
      },
      "source": [
        "acc = historyV.history['accuracy']\r\n",
        "val_acc = historyV.history['val_accuracy']\r\n",
        "loss = historyV.history['loss']\r\n",
        "val_loss = historyV.history['val_loss']\r\n",
        "\r\n",
        "num_epochs = range(len(acc))\r\n",
        "\r\n",
        "plt.figure(figsize=(7,7))\r\n",
        "\r\n",
        "plt.plot(num_epochs, acc, 'r', label='Training accuracy')\r\n",
        "plt.plot(num_epochs, val_acc, 'b', label='Validation accuracy')\r\n",
        "plt.title('Training and validation accuracy')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.figure(figsize=(7,7))\r\n",
        "\r\n",
        "plt.plot(num_epochs, loss, 'r', label='Training Loss')\r\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation Loss')\r\n",
        "plt.title('Training and validation loss')\r\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my2NVUJgSO9h"
      },
      "source": [
        "## Avaliação do modelo com a base de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlNsFLFp6yjS"
      },
      "source": [
        "test_images_path = glob.glob(test_path + '*/*.jpeg')\n",
        "x_test = []\n",
        "y_test = []\n",
        "for i in range(len(test_images_path)):\n",
        "    img = cv2.imread(test_images_path[i])\n",
        "    img = cv2.resize(img, (150,150))\n",
        "    img = np.array(img/255.0)\n",
        "    x_test.append(img)\n",
        "    if 'CNV' in test_images_path[i]:\n",
        "        y_test.append(0)\n",
        "    elif 'DME' in test_images_path[i]:\n",
        "        y_test.append(1)\n",
        "    elif 'DRUSEN' in test_images_path[i]:\n",
        "        y_test.append(2)\n",
        "    elif 'NORMAL' in test_images_path[i]:\n",
        "        y_test.append(3)\n",
        "y_test = np.array(y_test)\n",
        "x_test = np.array(x_test)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYfLKl4ITBJr"
      },
      "source": [
        "y_test_cat = tf.keras.utils.to_categorical(y_test)\r\n",
        "loss_and_metrics = modelV.evaluate(x_test, y_test_cat)\r\n",
        "\r\n",
        "y_pred = modelV.predict(x_test)\r\n",
        "y_pred = np.argmax(y_pred,axis=1)\r\n",
        "\r\n",
        "labels = ('CNV', 'DME', 'DRUSEN', 'NORMAL')\r\n",
        "\r\n",
        "y_actu = pd.Series(y_test, name='Actual')\r\n",
        "y_pred = pd.Series(y_pred, name='Predicted')\r\n",
        "df_confusion = pd.crosstab(y_actu, y_pred)\r\n",
        "\r\n",
        "df_conf_norm = df_confusion / df_confusion.sum(axis=1)\r\n",
        "print(df_confusion)\r\n",
        "print(df_conf_norm)\r\n",
        "\r\n",
        "plt.figure(figsize=(20, 20))\r\n",
        "plt.matshow(df_confusion, cmap=plt.get_cmap('Blues'), fignum=1)  # imshow\r\n",
        "plt.colorbar()\r\n",
        "tick_marks = np.arange(len(labels))\r\n",
        "plt.xticks(tick_marks, labels,fontsize=16, rotation=60)\r\n",
        "plt.yticks(tick_marks, labels, fontsize=16)\r\n",
        "thresh = 0.6\r\n",
        "\r\n",
        "for i in range(n_classes):\r\n",
        "    for j in range(n_classes):\r\n",
        "        plt.text(i, j, \"{:0.2f}%\".format(df_conf_norm[i][j] * 100),\r\n",
        "                 horizontalalignment='center',\r\n",
        "                 color='white' if df_conf_norm[i][j] > thresh else 'black',\r\n",
        "                fontsize = 16)\r\n",
        "\r\n",
        "# plt.tight_layout()\r\n",
        "plt.ylabel(df_confusion.index.name, fontsize=16)\r\n",
        "plt.xlabel(df_confusion.columns.name,fontsize=16)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Tkp9BitNpcd"
      },
      "source": [
        "# Xception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMsRJsCDOBoC"
      },
      "source": [
        "# Remover as camadas FC (Full Connected) do modelo Xception pré-treinado - carregar a rede VGG16,\r\n",
        "#certificando-se de que os conjuntos de camadas principais Full Connected (FC) sejam deixados de fora\r\n",
        "head_model = Xception(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\r\n",
        "\r\n",
        "# Remover as camadas FC (Full Connected) do modelo VGG-16 pré-treinado - carregar a rede VGG16,\r\n",
        "#certificando-se de que os conjuntos de camadas principais Full Connected (FC) sejam deixados de fora\r\n",
        "baseModel = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(width, height, 3)))\r\n",
        "\r\n",
        "# Construir as camadas Full Connected (FC) \"top\" do modelo, que substituirão a base da VGG16\r\n",
        "headModel = baseModel.output\r\n",
        "headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\r\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\r\n",
        "headModel = Dense(512, activation=\"relu\")(headModel)\r\n",
        "headModel = Dropout(0.5)(headModel)\r\n",
        "headModel = Dense(64, activation=\"relu\")(headModel)\r\n",
        "headModel = Dropout(0.5)(headModel)\r\n",
        "headModel = Dense(4, activation=\"softmax\")(headModel) # quatro categorias\r\n",
        "\r\n",
        "# Construir o modelo CNN\r\n",
        "modelX = Model(inputs=baseModel.input, outputs=headModel)\r\n",
        "\r\n",
        "# Faz um loop sobre todas as camadas no modelo base e as congela para que * não * sejam atualizadas durante o primeiro processo de treinamento\r\n",
        "for layer in baseModel.layers:\r\n",
        "    layer.trainable = False\r\n",
        "\r\n",
        "# Compilar o modelo\r\n",
        "opt = Adam(lr=init_lr, decay=init_lr / epochs)\r\n",
        "modelX.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\r\n",
        "\r\n",
        "plot_model(modelX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_cGbh6DRJ5M"
      },
      "source": [
        "## Treinando o Modelo "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HirH6PrFQ9JJ"
      },
      "source": [
        "# Callbacks\r\n",
        "es = EarlyStopping(patience=10,monitor=\"val_loss\")\r\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', patience=10)\r\n",
        "mc = ModelCheckpoint(filepath='best.h5', save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbeeLHmvRE9X"
      },
      "source": [
        "stepsValidation = validationGenerator.samples // batchSize\r\n",
        "stepsTraining = trainGenerator.samples // batchSize\r\n",
        "\r\n",
        "historyX = modelX.fit_generator(generator = trainGenerator,\r\n",
        "    steps_per_epoch = stepsTraining,\r\n",
        "    epochs=epochs,\r\n",
        "    validation_data = validationGenerator,\r\n",
        "    validation_steps = stepsValidation,\r\n",
        "    class_weight=class_weights,\r\n",
        "    callbacks=[es,rlr,mc]\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2k7OOoWRvgH"
      },
      "source": [
        "## Avaliação do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HU77b4hfRueI"
      },
      "source": [
        "acc = historyX.history['accuracy']\r\n",
        "val_acc = historyX.history['val_accuracy']\r\n",
        "loss = historyX.history['loss']\r\n",
        "val_loss = historyX.history['val_loss']\r\n",
        "\r\n",
        "num_epochs = range(len(acc))\r\n",
        "\r\n",
        "plt.figure(figsize=(7,7))\r\n",
        "\r\n",
        "plt.plot(num_epochs, acc, 'r', label='Training accuracy')\r\n",
        "plt.plot(num_epochs, val_acc, 'b', label='Validation accuracy')\r\n",
        "plt.title('Training and validation accuracy')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.figure(figsize=(7,7))\r\n",
        "\r\n",
        "plt.plot(num_epochs, loss, 'r', label='Training Loss')\r\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation Loss')\r\n",
        "plt.title('Training and validation loss')\r\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNcCrYNCSlkk"
      },
      "source": [
        "## Avaliação do modelo com a base de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYmcsv5nSac1"
      },
      "source": [
        "y_test_cat = tf.keras.utils.to_categorical(y_test)\r\n",
        "loss_and_metrics = modelV.evaluate(x_test, y_test_cat)\r\n",
        "\r\n",
        "y_pred = modelX.predict(x_test)\r\n",
        "y_pred = np.argmax(y_pred,axis=1)\r\n",
        "\r\n",
        "labels = ('CNV', 'DME', 'DRUSEN', 'NORMAL')\r\n",
        "\r\n",
        "y_actu = pd.Series(y_test, name='Actual')\r\n",
        "y_pred = pd.Series(y_pred, name='Predicted')\r\n",
        "df_confusion = pd.crosstab(y_actu, y_pred)\r\n",
        "\r\n",
        "df_conf_norm = df_confusion / df_confusion.sum(axis=1)\r\n",
        "print(df_confusion)\r\n",
        "print(df_conf_norm)\r\n",
        "\r\n",
        "plt.figure(figsize=(20, 20))\r\n",
        "plt.matshow(df_confusion, cmap=plt.get_cmap('Blues'), fignum=1)  # imshow\r\n",
        "plt.colorbar()\r\n",
        "tick_marks = np.arange(len(labels))\r\n",
        "plt.xticks(tick_marks, labels,fontsize=16, rotation=60)\r\n",
        "plt.yticks(tick_marks, labels, fontsize=16)\r\n",
        "thresh = 0.6"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}